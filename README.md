




# RAG-Based AI Assistant System - Complete Guide

Egy teljes k√∂r≈± RAG (Retrieval-Augmented Generation) alap√∫ AI asszisztens rendszer dokumentum feldolgoz√°s, vektoros keres√©s √©s √∂sszehangol√≥ LLM-vel. Ez az √∫tmutat√≥ v√©gigvezet a telep√≠t√©sen, konfigur√°ci√≥n √©s minden f≈ë komponens haszn√°lat√°n.

## üìã Tartalomjegyz√©k

1. [Projekt √Åttekint√©s](#projekt-√°ttekint√©s)
2. [Technol√≥giai Stack](#technol√≥giai-stack)
3. [El≈ëfelt√©telek](#el≈ëfelt√©telek)
4. [Gyors Ind√≠t√°s](#gyors-ind√≠t√°s)
5. [R√©szletes Telep√≠t√©si √ötmutat√≥](#r√©szletes-telep√≠t√©si-√∫tmutat√≥)
6. [1. Komponens: Dokumentumok Felt√∂lt√©se](#1-komponens-dokumentumok-felt√∂lt√©se)
7. [2. Komponens: AI Asszisztens](#2-komponens-ai-asszisztens)
8. [3. Komponens: Evalu√°ci√≥](#3-komponens-evalu√°ci√≥)
9. [Monitoroz√°s √©s K√∂lts√©gk√∂vet√©s](#monitoroz√°s-√©s-k√∂lts√©gk√∂vet√©s)
10. [Hibaelh√°r√≠t√°s](#hibaelh√°r√≠t√°s)
11. [Tov√°bbi Inform√°ci√≥k](#tov√°bbi-inform√°ci√≥k)

---

## Projekt √Åttekint√©s

Ez a rendszer egy komplett RAG asszisztens infrastrukt√∫ra, amely k√©pes:

- **Dokumentumok feldolgoz√°sa**: PDF, DOCX, TXT, Markdown, HTML form√°tumok t√°mogat√°s√°val
- **Intelligens chunking**: 4 k√ºl√∂nb√∂z≈ë strat√©gi√°val optimaliz√°lt sz√∂vegt√∂red√©kek
- **Vektoros keres√©s**: PostgreSQL + pgvector alap√∫ hasonl√≥s√°gi keres√©s
- **LLM-alap√∫ reranking**: Pontoss√°g jav√≠t√°sa felfel√© m√©r√©s≈±s√©ggel
- **RAG chat**: GPT-4o mini alap√∫ val√≥s idej≈± streaming v√°laszok
- **Teljes observability**: OpenTelemetry + Jaeger + Prometheus + Grafana nyomk√∂vet√©s
- **Komprehenz√≠v evalu√°ci√≥**: Retrieval, response quality, √©s multi-turn conversation √©rt√©kel√©s

**Dokumentum**: The Jungle Book (Rudyard Kipling)
**Felhaszn√°l√°si eset**: K√©rd√©s-v√°lasz asszisztens a k√∂nyv tartalm√°r√≥l

---

## Technol√≥giai Stack

### Backend
- **Database**: PostgreSQL 15+ + pgvector extension
- **Vector Storage**: pgvector (1536 dimenzi√≥k)
- **Document Processing**: Python + unstructured library
- **Embedding Model**: OpenAI text-embedding-3-small
- **LLM**: OpenAI GPT-4o mini
- **Deployment**: Docker + Docker Compose

### Frontend
- **Framework**: Next.js 15 (App Router)
- **UI**: React 18 + Tailwind CSS
- **AI Integration**: Vercel AI SDK
- **Language**: TypeScript

### Observability
- **Tracing**: OpenTelemetry + Jaeger
- **Metrics**: Prometheus
- **Visualization**: Grafana (8-panel cost tracking dashboard)
- **Cost Tracking**: OpenTelemetry metrics (embeddings, reranking, completions)

---

## El≈ëfelt√©telek

### System Requirements
- **macOS/Linux/Windows** (WSL aj√°nlott Windows-on)
- **Docker** √©s **Docker Compose** (1.29.0+)
- **Node.js** 18.x vagy √∫jabb (assistant komponenshez)
- **Python** 3.10+ (chunking pipeline-hez)
- **PostgreSQL client** (psql) - tesztel√©shez (opcion√°lis)

### API Keys & Services
- **OpenAI API Key** - Embedding √©s chat completions
- **OpenAI Credits** - Sz≈±ks a feldolgoz√°shoz (~$0.01-0.05 per teljes cycle)

### Lemezter√ºlet
- **~5GB** Docker images √©s adatb√°zis sz√°m√°ra
- **~1GB** Python f√ºgg≈ës√©gek

---

## Gyors Ind√≠t√°s

Teljes system ind√≠t√°sa **5 perc alatt**:

### 1. Projekt m√°sol√°sa
```bash
cd /path/to/project
```

### 2. Environment konfigur√°l√°sa
```bash
# M√°solja az .env.example-t
cp .env.example .env

# Szerkessze a .env f√°jlt √©s adja meg az OpenAI API kulcsot
OPENAI_API_KEY=sk-proj-your-actual-key-here
```

### 3. Docker kont√©nerek ind√≠t√°sa
```bash
docker-compose up -d
```

**V√°rjon 30-60 m√°sodpercet, am√≠g az adatb√°zis inicializ√°l√≥dik.**

Ellen≈ërz√©s:
```bash
docker ps  # L√°sd a fut√≥ kont√©nereket

# PostgreSQL ellen≈ërz√©se
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant -c "SELECT COUNT(*) FROM document_chunks;"
```

### 4. AI Asszisztens ind√≠t√°sa
```bash
cd assistant
npm install  # Els≈ë alkalommal
npm run dev
```

Az alkalmaz√°s el√©rhet≈ë lesz: **http://localhost:3000**

### 5. Tesztel√©s
√çrjon be egy k√©rd√©st:
- "Ki az a Mowgli?"
- "Mi az a Dzsungel T√∂rv√©nye?"
- "Mes√©lj nekem Shere Khan-r√≥l"

‚úÖ **K√©sz!** A system m≈±k√∂dik.

---

## R√©szletes Telep√≠t√©si √ötmutat√≥

### L√©p√©s 1: Docker Kont√©nerek Be√°ll√≠t√°sa

#### A. PostgreSQL + pgvector

```bash
# Kont√©ner ind√≠t√°sa
docker-compose up -d postgres

# Ellen≈ërizze a kont√©ner napl√≥it (erre 20-30s sz√ºks√©ges)
docker logs hf4-v1-postgres

# Kapcsol√≥djon az adatb√°zishoz
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant

# SQL parancsok az adatb√°zisban
CREATE EXTENSION vector;  -- pgvector extension

-- Documents t√°bla
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    file_path TEXT UNIQUE NOT NULL,
    file_name TEXT NOT NULL,
    file_type TEXT NOT NULL,
    file_size INTEGER NOT NULL,
    created_at TIMESTAMP,
    modified_at TIMESTAMP,
    metadata JSONB,
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Document chunks t√°bla
CREATE TABLE document_chunks (
    id SERIAL PRIMARY KEY,
    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
    chunk_id TEXT UNIQUE NOT NULL,
    content TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    metadata JSONB,
    token_count INTEGER,
    content_hash TEXT,
    embedding vector(1536),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Indexek
CREATE INDEX idx_chunks_document_id ON document_chunks(document_id);
CREATE INDEX idx_chunks_embedding ON document_chunks USING ivfflat (embedding vector_cosine_ops);
```

#### B. Observability Stack (Opcion√°lis, de aj√°nlott)

Az observability komponensek m√°r be vannak √°ll√≠tva a `docker-compose.yml`-ben:

```bash
# Jaeger (Tracing) - http://localhost:16686
docker-compose up -d jaeger

# Prometheus (Metrics) - http://localhost:9090
docker-compose up -d prometheus

# Grafana (Visualization) - http://localhost:3001
docker-compose up -d grafana

# OpenTelemetry Collector
docker-compose up -d otel-collector
```

#### C. Teljes Stack Ind√≠t√°sa

```bash
# Minden kont√©ner ind√≠t√°sa
docker-compose up -d

# Napl√≥k megtekint√©se
docker-compose logs -f postgres    # PostgreSQL napl√≥k
docker-compose logs -f jaeger      # Jaeger napl√≥k
docker-compose logs -f grafana     # Grafana napl√≥k

# Le√°ll√≠t√°s (adatok megmaradnak)
docker-compose stop

# Teljes t√∂rl√©s (adatok elvesznek!)
docker-compose down -v
```

---

### L√©p√©s 2: Python Chunking Pipeline Telep√≠t√©se

#### A. F√ºgg≈ës√©gek

```bash
cd chunking
pip install -r requirements.txt
```

#### B. Environment Konfigur√°l√°sa

A `.env` f√°jl m√°r tartalmaznia kell a sz√ºks√©ges konfigur√°ci√≥t a projekt gy√∂ker√©ben:

```bash
# Ellen≈ërizze/szerkessze a gy√∂k√©r .env f√°jlt
cat ../.env | grep -E "OPENAI|DB_|DEFAULT"
```

Sz√ºks√©ges env v√°ltoz√≥k:
```bash
OPENAI_API_KEY=sk-proj-...              # OpenAI API kulcs
DB_HOST=localhost
DB_PORT=5432
DB_NAME=rag_assistant
DB_USER=rag_user
DB_PASSWORD=rag_dev_password_2024
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```

#### C. Adatb√°zis Ellen≈ërz√©se

```bash
# Csatlakozzon az adatb√°zishoz
python -c "
import psycopg2
conn = psycopg2.connect(
    host='localhost',
    port=5432,
    database='rag_assistant',
    user='rag_user',
    password='rag_dev_password_2024'
)
cursor = conn.cursor()
cursor.execute('SELECT COUNT(*) FROM document_chunks;')
print(f'Chunks: {cursor.fetchone()[0]}')
cursor.close()
"
```

---

### L√©p√©s 3: Next.js Assistant Telep√≠t√©se

#### A. F√ºgg≈ës√©gek

```bash
cd assistant
npm install
```

#### B. Environment Konfigur√°l√°sa

A `.env.local` m√°r l√©tezik az assistant k√∂nyvt√°rban:

```bash
# Ellen≈ërizze az .env.local f√°jlt
cat .env.local
```

Sz√ºks√©ges env v√°ltoz√≥k:
```bash
OPENAI_API_KEY=sk-proj-...                                           # OpenAI API
DATABASE_URL=postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant

OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_EMBEDDING_DIMENSION=1536

DEFAULT_MATCH_COUNT=5
DEFAULT_MATCH_THRESHOLD=0.3
```

#### C. Build & Run

```bash
# Development m√≥dban
npm run dev
# El√©rhet≈ë: http://localhost:3000

# Production build
npm run build
npm start
```

---

## 1. Komponens: Dokumentumok Felt√∂lt√©se

### √Åttekint√©s

A dokumentum feldolgoz√°s pipeline a k√∂vetkez≈ë l√©p√©seket hajtja v√©gre:

```
Dokumentumok (PDF, DOCX, TXT, MD, HTML)
    ‚Üì
Dokumentum Bet√∂lt√©s (unstructured library)
    ‚Üì
Chunking (4 strat√©gia)
    ‚Üì
Embedding Gener√°l√°s (OpenAI text-embedding-3-small)
    ‚Üì
PostgreSQL/pgvector Felt√∂lt√©s
    ‚Üì
RAG K√©sz Adatb√°zis
```

### Chunking Strat√©gi√°k

#### 1. Szemantikus Chunking (Aj√°nlott)
```bash
cd chunking
python chunker.py \
    --input ../Documents/ \
    --strategy semantic \
    --upload
```

**El≈ënyei**:
- Meg≈ërzi a dokumentum strukt√∫r√°j√°t
- Tiszteletben tartja az √©rtelmes hat√°rokat (bekezd√©sek, fejl√©cek)
- Legjobb RAG teljes√≠tm√©ny

#### 2. Fix M√©ret≈± Chunking
```bash
python chunker.py \
    --input ../Documents/ \
    --strategy fixed \
    --chunk-size 512 \
    --chunk-overlap 50 \
    --upload
```

**El≈ënyei**:
- Konzisztens chunk m√©retek
- Kisz√°m√≠that√≥ token felhaszn√°l√°s
- Egyenletes feldolgoz√°s

#### 3. Rekurz√≠v Chunking
```bash
python chunker.py \
    --input ../Documents/ \
    --strategy recursive \
    --chunk-size 512 \
    --upload
```

**El≈ënyei**:
- Hierarchikus strukt√∫ra meg≈ërz√©se
- Markdown/struktur√°lt dokumentumokhoz j√≥
- Intelligens feloszt√°s

#### 4. Dokumentum T√≠pus Specifikus
```bash
python chunker.py \
    --input ../Documents/ \
    --strategy document_specific \
    --upload
```

**El≈ënyei**:
- Vegyes dokumentum t√≠pusok optim√°lis kezel√©se
- T√≠pus-tudatos feldolgoz√°s
- Automatikus form√°tum felismer√©s

### Parancssor Opci√≥k

| Opci√≥ | Le√≠r√°s | P√©lda |
|-------|--------|--------|
| `--input` | **K√∂telez≈ë**. F√°jl vagy k√∂nyvt√°r | `--input documents/` |
| `--strategy` | Chunking strat√©gia | `--strategy semantic` |
| `--chunk-size` | Chunk m√©ret (token) | `--chunk-size 512` |
| `--chunk-overlap` | √Åtv√©r√©s m√©rt√©ke | `--chunk-overlap 50` |
| `--upload` | Felt√∂lt√©s adatb√°zisba | `--upload` |
| `--batch-size` | Batch m√©ret embedding-ekhez | `--batch-size 50` |
| `--clear-progress` | Progress t√∂rl√©se | `--clear-progress` |
| `--log-level` | Log szint | `--log-level DEBUG` |

### Halad√≥ Opci√≥k

```bash
# Megl√©v≈ë progress folytat√°sa
python chunker.py --input documents/ --upload

# Progress t√∂rl√©se √©s √∫jraind√≠t√°s
python chunker.py --input documents/ --clear-progress --upload

# Konfigur√°ci√≥ valid√°l√°sa
python chunker.py --input documents/ --validate

# Debug m√≥dban
python chunker.py --input documents/ --log-level DEBUG

# Egy√©ni batch m√©ret
python chunker.py --input documents/ --batch-size 100 --upload
```

### Felhaszn√°l√°s M√°s Dokumentumokkal

```bash
# 1. Dokumentumokat m√°solja a Documents/ mapp√°ba
cp /path/to/your/document.pdf Documents/

# 2. Feldolgoz√°s
cd chunking
python chunker.py \
    --input ../Documents/ \
    --strategy semantic \
    --upload

# 3. El≈ëz≈ë dokumentumok elt√°vol√≠t√°sa (opcion√°lis)
# Adatb√°zis friss√≠t√©se - az UPDATE strategy be√°ll√≠t√°s a config.yaml-ben
# update_strategy: replace  (helyettes√≠t√©s)
# update_strategy: version  (verzion√°l√°s)
# update_strategy: upsert   (m√≥dos√≠t√°s)
```

### Figyelemmel K√≠s√©r√©s

```bash
# Progress file megtekint√©se
cat .chunking_progress.json

# Pipeline logok
tail -f chunking_pipeline.log

# Adatb√°zisban t√°rolt chunks
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant
> SELECT COUNT(*) FROM document_chunks;
```

### K√∂lts√©gbecsl√©s

Az OpenAI embedding API k√∂lts√©ge:

```python
from chunking.embeddings import EmbeddingGenerator

embedder = EmbeddingGenerator(api_key="your-key")
cost = embedder.estimate_cost(num_chunks=1000)
print(f"Becs√ºlt k√∂lts√©g: ${cost['estimated_cost_usd']}")

# text-embedding-3-small: $0.02 / 1M token
# √Åtlagos chunk: ~400 token
# 1000 chunk ‚âà $0.008
```

### Hibaelh√°r√≠t√°s - Dokumentum Felt√∂lt√©s

| Hiba | Megold√°s |
|------|----------|
| `OPENAI_API_KEY not set` | Adja meg az API kulcsot a `.env` f√°jlban |
| `Database connection failed` | Ellen≈ërizze, hogy PostgreSQL fut-e (`docker-compose up -d postgres`) |
| `pgvector extension not installed` | SQL-ben: `CREATE EXTENSION vector;` |
| `Rate limit exceeded` | Cs√∂kkentse a batch_size-t a config.yaml-ben |
| `File too large` | N√∂velje a `max_file_size_mb`-t a konfigban |

---

## 2. Komponens: AI Asszisztens

### √Åttekint√©s

A RAG chat asszisztens a feldolgozott dokumentumokb√≥l vektoros keres√©s seg√≠ts√©g√©vel gy≈±jt kontextust, √©s GPT-4o mini-vel gener√°l v√°laszokat.

### RAG Pipeline

```
User Query
    ‚Üì
Embedding Generation (OpenAI text-embedding-3-small)
    ‚Üì
Vector Search (pgvector cosine similarity)
    ‚Üì
Top 15 Chunk Retrieval
    ‚Üì
LLM Reranking (GPT-4o mini pointwise scoring)
    ‚Üì
Blended Scoring (70% LLM + 30% embedding)
    ‚Üì
Top 5 Selection
    ‚Üì
Context Assembly
    ‚Üì
System Prompt Preparation
    ‚Üì
GPT-4o mini Streaming Response
    ‚Üì
Browser Display (Real-time)
```

### Telep√≠t√©s & Futtat√°s

#### A. F√ºgg≈ës√©gek Telep√≠t√©se

```bash
cd assistant
npm install
```

#### B. Development Szerverind√≠t√°s

```bash
npm run dev
# El√©rhet≈ë: http://localhost:3000
```

#### C. Production Build

```bash
npm run build
npm start
```

### Haszn√°lat

1. **Nyissa meg az alkalmaz√°st**: http://localhost:3000
2. **√çrjon be egy k√©rd√©st** az input mez≈ëbe
3. **V√°jon a streaming v√°laszra**

P√©lda k√©rd√©sek:
- "Ki az a Mowgli √©s milyen a h√°ttere?"
- "Mi az a Dzsungel T√∂rv√©nye?"
- "√çrj le a kapcsolatot Mowgli √©s Baloo k√∂z√∂tt"
- "Ki az a Shere Khan √©s mi√©rt fontos?"
- "Milyen √°llatok √©lnek a dzsungelben ebben a t√∂rt√©netben?"

### Testreszab√°s

#### Vektor Keres√©s Param√©terei

`.env.local`:
```env
DEFAULT_MATCH_COUNT=5          # Visszaadott chunks (1-20)
DEFAULT_MATCH_THRESHOLD=0.3    # Minimum similarity (0.0-1.0)
```

#### LLM Param√©terek

`assistant/app/api/chat/route.ts`:
```typescript
const result = streamText({
  model: openai('gpt-4o-mini'),
  messages: modelMessages,
  temperature: 0.7,      // Kreativit√°s (0.0-1.0)
  maxTokens: 1000,       // Maximum hossz
});
```

#### System Prompt

`assistant/lib/rag.ts` ‚Üí `buildSystemPrompt()` f√ºggv√©ny szerkeszt√©se:
```typescript
export function buildSystemPrompt(context: string): string {
  return `Te egy seg√≠t≈ëk√©sz asszisztens vagy The Jungle Book k√∂nyvr≈ël.
V√°laszolj magyar nyelven a k√∂vetkez≈ë kontextus alapj√°n:

KONTEXTUS:
${context}

K√©rlek, v√°laszolj pontosan √©s t√∂m√∂ren.`;
}
```

### Backend Session Management

A rendszer automatikusan t√°rol minden besz√©lget√©st az adatb√°zisban:

```bash
# Session hist√≥ri√°j√°nak megtekint√©se
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant

> SELECT session_id, role, content, created_at
  FROM chat_messages
  ORDER BY created_at DESC
  LIMIT 10;

# Session √∂sszefoglal√≥k
> SELECT * FROM v_session_summary
  ORDER BY last_activity_at DESC
  LIMIT 5;
```

### Figyelemmel K√≠s√©r√©s

```bash
# API logok
npm run dev  # Ki√≠rja az API h√≠v√°sokat

# Chunk metaadat n√©zete
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant
> SELECT * FROM chat_rag_context
  WHERE chat_message_id = 'MESSAGE_ID'
  ORDER BY rank_position;
```

### Hibaelh√°r√≠t√°s - AI Asszisztens

| Hiba | Megold√°s |
|------|----------|
| "No relevant context found" | Cs√∂kkentse a `DEFAULT_MATCH_THRESHOLD`-ot |
| "Database connection failed" | Ellen≈ërizze a `DATABASE_URL` env v√°ltoz√≥t |
| "OpenAI API error" | Valid√°lja az `OPENAI_API_KEY`-t |
| "Streaming nem m≈±k√∂dik" | Ellen≈ërizze a b√∂ng√©sz≈ë konzolt (DevTools) |
| "Lass√∫ v√°laszok" | Cs√∂kkentse a `DEFAULT_MATCH_COUNT`-ot |

---

## 3. Komponens: Evalu√°ci√≥

A rendszer 3 szint≈± evalu√°ci√≥s rendszert biztos√≠t a RAG min≈ës√©g m√©r√©s√©re.

### 3.1 RAG-Level Evaluation (Retrieval Quality)

**Mit m√©r**: A vektoros keres√©s teljes√≠tm√©nye - h√°nyszor tal√°lja meg az eredeti chunk-ot a k√©rd√©s alapj√°n.

#### Telep√≠t√©s

```bash
cd rag-level-evaluation
pip install -r requirements.txt
```

#### Futtat√°s

```bash
# Teljes pipeline
python3 run_evaluation.py

# Megl√©v≈ë k√©rd√©sek haszn√°lata
python3 run_evaluation.py --skip-generation

# K√©rd√©sek √∫jragener√°l√°sa
python3 run_evaluation.py --regenerate

# Csak elemz√©s
python3 run_evaluation.py --skip-generation --skip-evaluation
```

#### L√©p√©senk√©nti Futtat√°s

```bash
# 1. K√©rd√©sgener√°l√°s
python3 generate_questions.py

# 2. RAG √©rt√©kel√©s
python3 evaluate_rag.py

# 3. Elemz√©s
python3 analyze_results.py
```

#### Kimeneti Metrik√°k

**Binary Single-Relevance Metrics**:
- **Hit Rate@K**: Az eredeti chunk megtal√°lhat√≥-e a top-K-ban?
- **First Position Accuracy**: Az eredeti chunk az els≈ë helyen van-e?
- **Average Rank**: √Åtlagos poz√≠ci√≥, ha megtal√°lhat√≥
- **Average Similarity**: √Åtlagos cosine similarity score

**Classical IR Metrics**:
- **MRR (Mean Reciprocal Rank)**: Az els≈ë relev√°ns chunk √°tlagos reciprok rangja
- **Precision@K**: A top-K k√∂z√ºl h√°ny relev√°ns (K=1,3,5,10)
- **Recall@K**: Az √∂sszes relev√°ns k√∂z√ºl h√°ny van a top-K-ban

**Embedding Quality Metrics**:
- **Separation Margin**: Relev√°ns vs irrelev√°ns similarity k√ºl√∂nbs√©ge
- **ROC-AUC**: Embedding model classification min≈ës√©ge (0-1)
- **Distribution Analysis**: Similarity score eloszl√°sai

**Chunk Quality Metrics**:
- **CSCI**: Chunk Size Consistency Index (konzisztencia)
- **RQCSB**: Retrieval Quality per Chunk Size Bucket (bucket teljes√≠tm√©ny)
- **PSS**: Position Stability Score (poz√≠ci√≥ stabilit√°sa)

#### Kimenetek

```
results/YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ summary.json              # Aggreg√°lt metrik√°k
‚îú‚îÄ‚îÄ detailed_results.csv      # Minden query r√©szletei
‚îú‚îÄ‚îÄ metrics_by_strategy.csv   # Strat√©gi√°nk√©nti bont√°s
‚îî‚îÄ‚îÄ plots/
    ‚îú‚îÄ‚îÄ overall_metrics.png          # Binary metrics
    ‚îú‚îÄ‚îÄ rank_distribution.png        # Rank eloszl√°s
    ‚îú‚îÄ‚îÄ similarity_distribution.png  # Similarity eloszl√°s
    ‚îú‚îÄ‚îÄ metrics_by_strategy.png      # Strat√©gia √∂sszehasonl√≠t√°s
    ‚îú‚îÄ‚îÄ precision_recall_curves.png  # P/R g√∂rb√©k
    ‚îú‚îÄ‚îÄ mrr_comparison.png           # MRR √∂sszehasonl√≠t√°s
    ‚îú‚îÄ‚îÄ embedding_quality.png        # Embedding elv√°laszt√°s
    ‚îú‚îÄ‚îÄ chunk_size_distribution.png  # Chunk m√©ret eloszl√°s
    ‚îî‚îÄ‚îÄ rqcsb_heatmap.png            # Bucket teljes√≠tm√©ny heatmap
```

#### Tipikus Eredm√©nyek

Egy j√≥ RAG rendszern√©l v√°rhat√≥:
- **Hit Rate@5**: 80-95%
- **First Position Accuracy**: 60-80%
- **MRR**: 0.65-0.85
- **Separation Margin**: > 0.2 (j√≥) vagy > 0.3 (kiv√°l√≥)
- **ROC-AUC**: 0.8+ (j√≥) vagy 0.9+ (kiv√°l√≥)

---

### 3.2 Single-Turn Evaluation (Response Quality)

**Mit m√©r**: A gener√°lt v√°laszok min≈ës√©ge - helyes-e √©s relev√°ns-e az asszisztens v√°lasza.

#### Telep√≠t√©s

```bash
cd single-turn-evaluation
pip install -r requirements.txt
```

#### Futtat√°s

```bash
# Teljes pipeline (aj√°nlott)
python3 scripts/1_generate_golden_dataset.py   # Golden Q&A dataset
python3 scripts/2_run_assistant.py             # RAG futtat√°s
python3 scripts/3_evaluate_correctness.py      # Helyes-e?
python3 scripts/4_evaluate_relevance.py        # Relev√°ns-e?
python3 scripts/5_analyze_results.py           # Elemz√©s & chartok
```

#### Kimeneti Metrik√°k

**Correctness**: Megegyezik-e az asszisztens v√°lasza a ground truth-tal?
- **CORRECT**: Teljesen helyes v√°lasz
- **INCORRECT**: Helytelen vagy hi√°nyz√≥ inform√°ci√≥

**Relevance**: Relev√°ns-e a v√°lasz a k√©rd√©shez?
- **RELEVANT**: K√∂zvetlen√ºl v√°laszt az asszisztens
- **IRRELEVANT**: Nem kapcsol√≥d√≥ tartalom

#### Kimenetek

```
single-turn-evaluation/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ golden_dataset.json          # Gener√°lt Q&A p√°rok (20-25 k√©rd√©s)
‚îÇ   ‚îú‚îÄ‚îÄ assistant_responses.json     # Asszisztens v√°laszok
‚îÇ   ‚îú‚îÄ‚îÄ correctness_evaluation.json  # Helyes/helytelen besorol√°s
‚îÇ   ‚îî‚îÄ‚îÄ relevance_evaluation.json    # Relev√°ns/irrelev√°ns besorol√°s
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ summary_report.md            # Text √∂sszefoglal√≥
‚îÇ   ‚îú‚îÄ‚îÄ overall_metrics.png          # Metrika chart
‚îÇ   ‚îú‚îÄ‚îÄ by_category.png              # Kateg√≥ria szerinti bont√°s
‚îÇ   ‚îî‚îÄ‚îÄ by_difficulty.png            # Neh√©zs√©g szerinti bont√°s
```

#### Tipikus Eredm√©nyek

Egy j√≥ asszisztens v√°rhat√≥ teljes√≠tm√©nye:
- **Correctness Rate**: 75-95%
- **Relevance Rate**: 85-100%
- **Both Correct & Relevant**: 70-90%

---

### 3.3 Multi-Turn Evaluation (Conversation Quality)

**Mit m√©r**: A multi-turn besz√©lget√©sek min≈ës√©ge - mennyire j√≥ az asszisztens t√∂bbk√∂r√∂s interakci√≥ban.

#### Telep√≠t√©s

```bash
cd multi-turn-evaluation
pip install -r requirements.txt
```

#### Futtat√°s

```bash
# Teljes batch (30 persona-goal kombin√°c√≥)
python3 run_multi_turn_evaluation.py --batch

# Specifikus persona-goal kombin√°ci√≥
python3 run_multi_turn_evaluation.py --goal mowgli_identity --persona patient_intermediate

# Egy√©ni max k√∂rsz√°m
python3 run_multi_turn_evaluation.py --goal jungle_ecosystem --persona curious_expert --max-turns 15
```

#### El√©rhet≈ë Personas

| Persona | T√ºrelmess√©g | Szak√©rtelem | Jellemz√©s |
|---------|-------------|-------------|----------|
| `patient_intermediate` | Magas (3 rossz) | K√∂zepes | T√ºrelmes, k√∂zepes szint≈± tud√°s |
| `impatient_beginner` | Alacsony (1 rossz) | Kezd≈ë | T√ºrelmetlen, kev√©s el≈ëismeret |
| `curious_expert` | Nagyon magas (5+) | Szak√©rt≈ë | K√≠v√°ncsi, m√©ly meg√©rt√©s |

#### El√©rhet≈ë Goals

**Mintak√©nt** (teljesebb lista a `goals.py` f√°jlban):
- `mowgli_identity`: Ki az a Mowgli?
- `jungle_ecosystem`: A dzsungel szerkezete
- `book_author`: A szerz≈ë inform√°ci√≥ja
- `character_relationships`: Karakterek k√∂z√∂tti kapcsolatok
- ...t√∂bb mint 10 goal

#### Evalu√°ci√≥ Dimenzi√≥i

| Dimenzi√≥ | Mit m√©r | S√∫ly |
|----------|---------|------|
| **Goal Achievement** | El√©rte-e az asszisztens a c√©lokat? | 40% |
| **Conversation Quality** | Koherencia, term√©szetess√©g, info min≈ës√©g | 20% |
| **Response Relevance** | Relevancia √©s pontoss√°g | 20% |
| **User Experience** | Frustr√°ci√≥szint, persona megfelel≈ës√©g | 10% |
| **Efficiency** | K√∂rsz√°m optimaliz√°l√°sa, redundancia | 10% |

#### Kimenetek

```
multi-turn-evaluation/results/
‚îú‚îÄ‚îÄ summary_table.csv                    # √ñsszes√≠tett eredm√©nyek
‚îú‚îÄ‚îÄ persona_goal_results_TIMESTAMP.json  # R√©szletes JSON results
‚îú‚îÄ‚îÄ dimension_breakdown.png              # Dimenzi√≥ teljes√≠tm√©ny
‚îî‚îÄ‚îÄ goal_achievement_heatmap.png         # Goal el√©r√©si heatmap
```

#### Tipikus Eredm√©nyek

Egy j√≥ multi-turn asszisztens v√°rhat√≥:
- **Goal Achievement**: 70-90%
- **Conversation Quality**: 75-90%
- **Response Relevance**: 80-95%
- **Overall Score**: 75-85%

---

### Evalu√°ci√≥ √ñsszehasonl√≠t√°sa

| Evalu√°ci√≥ T√≠pus | Mit M√©r | K√∂lt | Fut√°si Id≈ë | Javasolt Gyakoris√°g |
|-----------------|---------|------|-----------|-------------------|
| **RAG-Level** | Retrieval teljes√≠tm√©ny | ~$0.00005 | 3-10 perc | Chunking m√≥dos√≠t√°s ut√°n |
| **Single-Turn** | Response quality | ~$0.002 | 2-5 perc | Napi |
| **Multi-Turn** | Conversation quality | ~$0.001 | 5-15 perc | Heti |

---

## Monitoroz√°s √©s K√∂lts√©gk√∂vet√©s

### OpenTelemetry + Grafana

A rendszer teljes cost tracking √©s performance monitoring-ot biztos√≠t.

#### Dashboards

**Jaeger (Distributed Tracing)**:
- URL: http://localhost:16686
- Mit mutat: RAG pipeline span-ok, latency breakdown
- Hasznos: Bottleneck azonos√≠t√°s

**Prometheus (Metrics)**:
- URL: http://localhost:9090
- Mit mutat: Cost √©s token metrics
- Hasznos: Trend anal√≠zis

**Grafana (Visualization)**:
- URL: http://localhost:3001
- Bejelentkez√©s: `admin` / `admin`
- Dashboard: "RAG Assistant - Cost Tracking"
- Mutat: 8-panel cost breakdown

#### El√©rhet≈ë Metrik√°k

```
# RAG Pipeline k√∂lts√©gei
rag_assistant_rag_cost_embedding_USD_total
rag_assistant_rag_cost_reranking_USD_total
rag_assistant_rag_cost_chat_completion_USD_total

# Evalu√°ci√≥ k√∂lts√©gei
rag_assistant_rag_cost_evaluation_llm_usd_USD_total

# Token felhaszn√°l√°s
rag_assistant_rag_tokens_embedding_total
rag_assistant_rag_tokens_llm_input_total
rag_assistant_rag_tokens_llm_output_total
```

#### T√≠pikus K√∂lts√©gek

| M≈±velet | K√∂lts√©g | Le√≠r√°s |
|--------|---------|--------|
| **RAG k√©r√©s** | $0.001-0.002 | Embedding + reranking + completion |
| **RAG-level eval** | $0.00002/k√©rd√©s | Question generation |
| **Single-turn eval** | $0.002/25 Q&A | 3 LLM judge h√≠v√°s |
| **Multi-turn eval** | $0.001/konvers√°ci√≥ | 5 LLM judge h√≠v√°s |

### Grafana Dashboard Import√°l√°sa

1. **Grafana megnyit√°sa**: http://localhost:3001
2. **Dashboard Import**: Men√º ‚Üí Dashboards ‚Üí Import
3. **JSON bet√∂lt√©se**: `grafana-dashboard-costs.json`
4. **Save**: Ment√©s az alap√©rtelmezett datasource-val

---

## Hibaelh√°r√≠t√°s

### Docker Probl√©m√°k

#### Kont√©nerek nem indulnak

```bash
# Ellen≈ërizze a napl√≥kat
docker-compose logs postgres
docker-compose logs jaeger

# K√∂v logok k√∂vet√©se
docker-compose logs -f

# Hardv√©r reset
docker-compose down -v
docker-compose up -d
```

#### Port m√°r haszn√°latban

```bash
# Keresse meg a folyamatot
lsof -i :5432   # PostgreSQL
lsof -i :3001   # Grafana
lsof -i :16686  # Jaeger

# √Åll√≠tsa le
kill -9 <PID>

# Vagy m√≥dos√≠tsa a docker-compose.yml portokat
```

### Database Probl√©m√°k

#### Nincs csatlakoz√°s az adatb√°zishoz

```bash
# Tesztkezel√©s
psql -h localhost -p 5432 -U rag_user -d rag_assistant

# Jelsz√≥ be√≠r√°skor: rag_dev_password_2024
```

#### pgvector nincs telep√≠tve

```bash
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant

> CREATE EXTENSION vector;
```

#### Nincs chunk az adatb√°zisban

```bash
# Chunking futtat√°sa
cd chunking
python chunker.py --input ../Documents/ --strategy semantic --upload

# Ellen≈ëriz√©s
psql postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant
> SELECT COUNT(*) FROM document_chunks;
```

### Python/Chunking Probl√©m√°k

#### ImportError: unstructured

```bash
pip install unstructured[all-docs]
# Ha az tov√°bbra sem m≈±k√∂dik:
pip install pdf2image pdfplumber pillow
```

#### OpenAI API Hiba

```bash
# Ellen≈ërizze az API kulcsot
echo $OPENAI_API_KEY

# Valid√°ci√≥
curl -H "Authorization: Bearer $OPENAI_API_KEY" https://api.openai.com/v1/models
```

#### Rate Limit

```bash
# Cs√∂kkentse a batch size-t
python chunker.py --input documents/ --batch-size 20 --upload
```

### Next.js Probl√©m√°k

#### npm install hiba

```bash
# Clean install
rm -rf node_modules package-lock.json
npm install
```

#### Build hiba

```bash
# Clear Next cache
rm -rf .next
npm run build
```

#### Streaming nem m≈±k√∂dik

```bash
# Ellen≈ërizze az API route-ot
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "test"}]}'
```

### Evaluation Probl√©m√°k

#### "No chunks found"

```bash
# Gy≈ëz≈ëdj√∂n meg, hogy van chunk az adatb√°zisban
python -c "
import psycopg2
conn = psycopg2.connect('postgresql://rag_user:rag_dev_password_2024@localhost:5432/rag_assistant')
cur = conn.cursor()
cur.execute('SELECT COUNT(*) FROM document_chunks')
print(f'Total chunks: {cur.fetchone()[0]}')
"
```

#### Lass√∫ evalu√°ci√≥

- **RAG-Level**: Norm√°lis 1-2s/chunk (OpenAI API)
- **Single-Turn**: Norm√°lis 3-5 perc / 25 k√©rd√©s
- **Multi-Turn**: Norm√°lis 2-5 perc / konvers√°ci√≥

#### OpenAI API Limit

```bash
# Rate limit kezel√©s - automatikus retry logika
# Ha tov√°bbra is probl√©m√°s, cs√∂kkentsen a API h√≠v√°sok sz√°m√°n
```

---

## Tov√°bbi Inform√°ci√≥k

### Dokument√°ci√≥

- **CLAUDE.md**: Claude Code projekt instrukcci√≥k
- **REQUIREMENTS.md**: R√©szletes technikai k√∂vetelm√©nyek
- **SESSION_MANAGEMENT.md**: Conversation history implement√°ci√≥
- **chunking/README.md**: Chunking pipeline dokument√°ci√≥
- **assistant/README.md**: AI Asszisztens dokument√°ci√≥
- **rag-level-evaluation/README.md**: Retrieval evalu√°ci√≥
- **single-turn-evaluation/README.md**: Response evalu√°ci√≥
- **multi-turn-evaluation/README.md**: Conversation evalu√°ci√≥

### Projekt Szerkezet

```
/
‚îú‚îÄ‚îÄ chunking/                    # Dokumentum feldolgoz√°s
‚îú‚îÄ‚îÄ assistant/                   # Next.js chat UI
‚îú‚îÄ‚îÄ rag-level-evaluation/        # Retrieval √©rt√©kel√©s
‚îú‚îÄ‚îÄ single-turn-evaluation/      # Response √©rt√©kel√©s
‚îú‚îÄ‚îÄ multi-turn-evaluation/       # Conversation √©rt√©kel√©s
‚îú‚îÄ‚îÄ database/                    # DB schema & migrations
‚îú‚îÄ‚îÄ Documents/                   # Input dokumentumok (The Jungle Book)
‚îú‚îÄ‚îÄ docker-compose.yml           # Docker konfigur√°l√°s
‚îú‚îÄ‚îÄ .env                         # Environment v√°ltoz√≥k
‚îú‚îÄ‚îÄ prometheus.yml               # Prometheus config
‚îú‚îÄ‚îÄ otel-collector-config.yaml   # OpenTelemetry config
‚îú‚îÄ‚îÄ grafana-dashboard-costs.json # Grafana dashboard
‚îú‚îÄ‚îÄ REQUIREMENTS.md              # K√∂vetelm√©nyek
‚îú‚îÄ‚îÄ CLAUDE.md                    # Claude instrukci√≥k
‚îî‚îÄ‚îÄ README.md                    # Ez a f√°jl
```

### Legjobb Gyakorlatok

#### Dokumentum Feldolgoz√°s
1. V√°lassza a **semantic** chunking-ot a legt√∂bb esetben
2. **Tesztelje** peque√±o dokumentumon el≈ëbb
3. **Figyelmmel k√≠s√©rje** az embedding k√∂lts√©geket
4. **Valid√°lja** a chunk min≈ës√©get el≈ëbb

#### AI Asszisztens
1. **Hangoljon** a `DEFAULT_MATCH_THRESHOLD` √©rt√©ken
2. **Teszteljen** k√ºl√∂nb√∂z≈ë system prompt-okkal
3. **Monitorozzon** a Grafana dashboardon
4. **Optimaliz√°ljon** reranking param√©tereken

#### Evalu√°ci√≥
1. **Futtassa el≈ësz√∂r** a RAG-level evalu√°ci√≥t
2. **Majd** a Single-turn evalu√°ci√≥t
3. **V√©g√ºl** a Multi-turn evalu√°ci√≥t
4. **Iter√°ljon** a megl√©p√©sek alapj√°n

### Szok√°sos Workflow

```
1. SETUP (Egyszeri)
   ‚îî‚îÄ Docker containers
   ‚îî‚îÄ Python & Node.js environment

2. INGESTION (Dokumentum felt√∂lt√©s)
   ‚îî‚îÄ Documents m√°sol√°sa Documents/
   ‚îî‚îÄ Chunking pipeline futtat√°sa
   ‚îî‚îÄ Adatb√°zis ellen≈ërz√©se

3. TESTING (AI asszisztens)
   ‚îî‚îÄ npm run dev
   ‚îî‚îÄ K√©rd√©sek tesztel√©se
   ‚îî‚îÄ Response min≈ës√©g ellen≈ërz√©se

4. EVALUATION (Min≈ës√©g m√©r√©s)
   ‚îî‚îÄ RAG-level evaluation
   ‚îî‚îÄ Single-turn evaluation
   ‚îî‚îÄ Multi-turn evaluation

5. OPTIMIZATION (Finomhangol√°s)
   ‚îî‚îÄ Metrikai alapj√°n m√≥dos√≠t√°s
   ‚îî‚îÄ Iter√°l√°s 3-4 k√∂z√∂tt
   ‚îî‚îÄ K√∂lts√©gk√∂vet√©s (Grafana)

6. MONITORING (Termel√©s)
   ‚îî‚îÄ Jaeger: trace Analysis
   ‚îî‚îÄ Prometheus: metric trends
   ‚îî‚îÄ Grafana: cost dashboard
```

### Support & Troubleshooting

**Probl√©ma?**
1. N√©zze meg a fenti Hibaelh√°r√≠t√°s szekci√≥t
2. Ellen≈ërizze a komponens-specifikus README-ket
3. N√©zze meg a logokat: `docker logs`, `npm run dev`, `tail -f chunking_pipeline.log`
4. Tesztelje az API-t curl-lel vagy Postman-nel

**API Tesztel√©s**:
```bash
# RAG Chat API
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {
        "role": "user",
        "content": "Who is Mowgli?"
      }
    ]
  }'
```

---

## Version History

- **1.0.0** (2025-11-18): Teljes dokument√°ci√≥
  - Gyors ind√≠t√°s √∫tmutat√≥
  - 3 komponens r√©szletes √∫tmutat√≥
  - Monitoroz√°s √©s k√∂lts√©gk√∂vet√©s
  - Hibaelh√°r√≠t√°s
  - Best practices

---

## Licensz

Ez a projekt az AI asszisztens fejleszt√©si projekt r√©sze.

---

## Kontakt & T√°mogat√°s

K√©rd√©sek vagy probl√©m√°k eset√©n:
1. Ellen≈ërizze a fenti dokument√°ci√≥t
2. Keresse meg az [Hibaelh√°r√≠t√°s](#hibaelh√°r√≠t√°s) szekci√≥t
3. N√©zze meg a komponens-specifikus README f√°jlokat
4. Ellen≈ërizze a logokat Debug m√≥dban

**Konfigur√°lhat√≥ komponensek**:
- Chunking strat√©gia
- Vector search param√©terek
- LLM prompt √©s be√°ll√≠t√°sok
- Evalu√°ci√≥ konfigur√°l√°sa

**Monitoring&Observability**:
- Jaeger: http://localhost:16686
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3001

---

**J√≥ munk√°t! üöÄ**
