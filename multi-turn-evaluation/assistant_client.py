"""
RAG Assistant Backend Kliens - End-to-End kommunikÃ¡ciÃ³.

Ez a modul felelÅ‘s a Next.js backend API-val valÃ³ kommunikÃ¡ciÃ³Ã©rt.
POST kÃ©rÃ©st kÃ¼ld a /api/chat endpointra Ã©s feldolgozza a streaming vÃ¡laszt.

Backend endpoint:
- URL: http://localhost:3000/api/chat
- Method: POST
- Input: { messages: [{ role: "user"|"assistant", content: string }] }
- Output: Streaming text response (Server-Sent Events)

A kliens tÃ¡mogatja:
- Streaming vÃ¡laszok kezelÃ©sÃ©t
- Session management (automatikus a backend oldalon)
- ÃšjraprÃ³bÃ¡lkozÃ¡s hibÃ¡k esetÃ©n
- Timeout kezelÃ©s
"""

import requests
import json
import os
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
import time

load_dotenv()


class AssistantClient:
    """
    RAG Assistant Backend kliens.

    Ez a kliens end-to-end kommunikÃ¡ciÃ³t biztosÃ­t a Next.js backend API-val.
    """

    def __init__(
        self,
        base_url: str = None,
        timeout: int = 60,
        max_retries: int = 3
    ):
        """
        InicializÃ¡lÃ¡s.

        Args:
            base_url: Backend URL (alapÃ©rtelmezett: http://localhost:3000)
            timeout: Timeout mÃ¡sodpercekben (alapÃ©rtelmezett: 60)
            max_retries: Maximum ÃºjraprÃ³bÃ¡lkozÃ¡sok szÃ¡ma (alapÃ©rtelmezett: 3)
        """
        self.base_url = base_url or os.getenv("ASSISTANT_BASE_URL", "http://localhost:3000")
        self.chat_endpoint = f"{self.base_url}/api/chat"
        self.timeout = timeout
        self.max_retries = max_retries

    def send_message(
        self,
        messages: List[Dict[str, str]],
        stream: bool = True
    ) -> Dict[str, Any]:
        """
        Ãœzenet kÃ¼ldÃ©se a backend-nek.

        Args:
            messages: Ãœzenetek listÃ¡ja [{ role: "user"|"assistant", content: str }]
            stream: Streaming engedÃ©lyezÃ©se (alapÃ©rtelmezett: True)

        Returns:
            Dict az eredmÃ©nnyel:
            {
                "success": bool,
                "response": str,  # Assistant vÃ¡lasza
                "error": Optional[str],
                "metadata": {
                    "duration_ms": int,
                    "response_length": int,
                    "streaming": bool
                },
                "performance": {
                    "total_duration_ms": int,
                    "api_latency_ms": int,
                    "ttft_ms": int,  # Time To First Token (streaming only)
                    "response_tokens": int,  # Approximate token count
                    "tokens_per_second": float,
                    "retry_count": int
                }
            }

        PÃ©lda:
            >>> client = AssistantClient()
            >>> result = client.send_message([
            ...     {"role": "user", "content": "Ki az a Maugli?"}
            ... ])
            >>> print(result["response"])
        """
        start_time = time.time()

        # Request payload
        payload = {
            "messages": messages
        }

        # ÃšjraprÃ³bÃ¡lkozÃ¡s logika
        for attempt in range(self.max_retries):
            try:
                api_start = time.time()

                if stream:
                    # Streaming request with performance tracking
                    response, perf_metrics = self._send_streaming_request(payload)
                else:
                    # Non-streaming request (egyszerÅ±bb tesztelÃ©shez)
                    response = self._send_regular_request(payload)
                    perf_metrics = {}

                api_duration = time.time() - api_start
                total_duration = time.time() - start_time

                # Token counting (approximate: split by whitespace)
                response_tokens = len(response.split())
                tokens_per_sec = response_tokens / api_duration if api_duration > 0 else 0

                return {
                    "success": True,
                    "response": response,
                    "error": None,
                    "metadata": {
                        "duration_ms": int(total_duration * 1000),
                        "response_length": len(response),
                        "streaming": stream,
                        "attempt": attempt + 1
                    },
                    "performance": {
                        "total_duration_ms": int(total_duration * 1000),
                        "api_latency_ms": int(api_duration * 1000),
                        "ttft_ms": perf_metrics.get("ttft_ms", None),
                        "response_tokens": response_tokens,
                        "tokens_per_second": round(tokens_per_sec, 2),
                        "retry_count": attempt
                    }
                }

            except Exception as e:
                error_msg = str(e)
                print(f"Attempt {attempt + 1}/{self.max_retries} failed: {error_msg}")

                if attempt == self.max_retries - 1:
                    # UtolsÃ³ prÃ³bÃ¡lkozÃ¡s, return error
                    duration_ms = int((time.time() - start_time) * 1000)
                    return {
                        "success": False,
                        "response": "",
                        "error": error_msg,
                        "metadata": {
                            "duration_ms": duration_ms,
                            "response_length": 0,
                            "streaming": stream,
                            "attempt": attempt + 1
                        },
                        "performance": {
                            "total_duration_ms": duration_ms,
                            "api_latency_ms": None,
                            "ttft_ms": None,
                            "response_tokens": 0,
                            "tokens_per_second": 0,
                            "retry_count": attempt
                        }
                    }

                # VÃ¡rakozÃ¡s ÃºjraprÃ³bÃ¡lkozÃ¡s elÅ‘tt (exponential backoff)
                time.sleep(2 ** attempt)

        # Nem kellene ide eljutni, de biztonsÃ¡gi hÃ¡lÃ³
        duration_ms = int((time.time() - start_time) * 1000)
        return {
            "success": False,
            "response": "",
            "error": "Max retries exceeded",
            "metadata": {
                "duration_ms": duration_ms,
                "response_length": 0,
                "streaming": stream,
                "attempt": self.max_retries
            },
            "performance": {
                "total_duration_ms": duration_ms,
                "api_latency_ms": None,
                "ttft_ms": None,
                "response_tokens": 0,
                "tokens_per_second": 0,
                "retry_count": self.max_retries
            }
        }

    def _send_streaming_request(self, payload: Dict[str, Any]) -> tuple[str, Dict[str, Any]]:
        """
        Streaming POST request kÃ¼ldÃ©se performance tracking-gel.

        Args:
            payload: Request payload

        Returns:
            Tuple of (response text, performance metrics dict)

        Raises:
            Exception: Ha a request sikertelen
        """
        request_start = time.time()

        response = requests.post(
            self.chat_endpoint,
            json=payload,
            timeout=self.timeout,
            stream=True,
            headers={
                "Content-Type": "application/json",
                "Accept": "text/event-stream"
            }
        )

        # StÃ¡tusz ellenÅ‘rzÃ©s
        if response.status_code != 200:
            error_text = response.text
            try:
                error_json = response.json()
                error_msg = error_json.get("message", error_text)
            except:
                error_msg = error_text
            raise Exception(f"HTTP {response.status_code}: {error_msg}")

        # Streaming response feldolgozÃ¡sa performance tracking-gel
        full_response = ""
        first_token_time = None
        token_count = 0

        for line in response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')

                # Vercel AI SDK stream formÃ¡tum: 0:"text"
                # PÃ©ldÃ¡ul: 0:"M", 0:"aug", 0:"li"
                if ':' in decoded_line:
                    try:
                        # Split elsÅ‘ kettÅ‘spontnÃ¡l
                        parts = decoded_line.split(':', 1)
                        if len(parts) == 2:
                            # MÃ¡sodik rÃ©sz JSON string: "M", "aug", stb.
                            content = json.loads(parts[1])
                            if isinstance(content, str):
                                # TTFT tracking: elsÅ‘ token idÅ‘pont
                                if first_token_time is None and content:
                                    first_token_time = time.time()

                                full_response += content
                                token_count += 1
                    except (json.JSONDecodeError, ValueError):
                        # Ha nem sikerÃ¼l parse-olni, prÃ³bÃ¡ljuk meg SSE formÃ¡tumkÃ©nt
                        pass

                # Server-Sent Events formÃ¡tum fallback: "data: {...}"
                if decoded_line.startswith('data: '):
                    data_str = decoded_line[6:]  # "data: " prefix levÃ¡gÃ¡sa

                    # Skip [DONE] marker
                    if data_str.strip() == '[DONE]':
                        break

                    try:
                        data = json.loads(data_str)

                        # Vercel AI SDK formÃ¡tum: {"type":"text","value":"..."}
                        if isinstance(data, dict):
                            if 'type' in data and data['type'] == 'text':
                                content = data.get('value', '')
                                if first_token_time is None and content:
                                    first_token_time = time.time()
                                full_response += content
                                token_count += 1
                            # OpenAI API formÃ¡tum
                            elif 'choices' in data and len(data['choices']) > 0:
                                delta = data['choices'][0].get('delta', {})
                                content = delta.get('content', '')
                                if first_token_time is None and content:
                                    first_token_time = time.time()
                                full_response += content
                                token_count += 1
                            # EgyszerÅ±sÃ­tett formÃ¡tum
                            elif 'content' in data:
                                if first_token_time is None and data['content']:
                                    first_token_time = time.time()
                                full_response += data['content']
                                token_count += 1
                    except json.JSONDecodeError:
                        continue

        # Performance metrics
        perf_metrics = {}
        if first_token_time:
            ttft_ms = int((first_token_time - request_start) * 1000)
            perf_metrics["ttft_ms"] = ttft_ms

        perf_metrics["stream_tokens"] = token_count

        return full_response.strip(), perf_metrics

    def _send_regular_request(self, payload: Dict[str, Any]) -> str:
        """
        Nem-streaming POST request kÃ¼ldÃ©se.

        Args:
            payload: Request payload

        Returns:
            Response text

        Raises:
            Exception: Ha a request sikertelen
        """
        response = requests.post(
            self.chat_endpoint,
            json=payload,
            timeout=self.timeout,
            headers={"Content-Type": "application/json"}
        )

        # StÃ¡tusz ellenÅ‘rzÃ©s
        if response.status_code != 200:
            error_text = response.text
            try:
                error_json = response.json()
                error_msg = error_json.get("message", error_text)
            except:
                error_msg = error_text
            raise Exception(f"HTTP {response.status_code}: {error_msg}")

        # Response feldolgozÃ¡sa
        try:
            result = response.json()
            return result.get("response", "")
        except json.JSONDecodeError:
            return response.text

    def send_conversation(
        self,
        conversation: List[Dict[str, str]]
    ) -> Dict[str, Any]:
        """
        Teljes beszÃ©lgetÃ©s elkÃ¼ldÃ©se (multi-turn support).

        Args:
            conversation: BeszÃ©lgetÃ©s lista
                [
                    {"role": "user", "content": "..."},
                    {"role": "assistant", "content": "..."},
                    {"role": "user", "content": "..."}
                ]

        Returns:
            Dict az eredmÃ©nnyel (ugyanaz, mint send_message)

        PÃ©lda:
            >>> client = AssistantClient()
            >>> conversation = [
            ...     {"role": "user", "content": "Ki az a Maugli?"},
            ...     {"role": "assistant", "content": "Maugli egy emberi gyerek..."},
            ...     {"role": "user", "content": "Ã‰s ki nevelte fel?"}
            ... ]
            >>> result = client.send_conversation(conversation)
        """
        return self.send_message(conversation)

    def health_check(self) -> bool:
        """
        Backend health check.

        Returns:
            True ha a backend elÃ©rhetÅ‘, False egyÃ©bkÃ©nt
        """
        try:
            response = requests.get(
                f"{self.base_url}/",
                timeout=5
            )
            return response.status_code == 200
        except:
            return False


# ============================================================================
# CONVENIENCE FUNCTIONS
# ============================================================================

def create_message(role: str, content: str) -> Dict[str, str]:
    """
    Ãœzenet objektum lÃ©trehozÃ¡sa.

    Args:
        role: "user" vagy "assistant"
        content: Ãœzenet tartalma

    Returns:
        Message dict
    """
    if role not in ["user", "assistant"]:
        raise ValueError(f"Invalid role: {role}. Must be 'user' or 'assistant'")

    return {
        "role": role,
        "content": content
    }


def format_conversation_history(
    conversation: List[Dict[str, str]]
) -> str:
    """
    BeszÃ©lgetÃ©s formÃ¡zÃ¡sa emberbarÃ¡t formÃ¡tumba.

    Args:
        conversation: BeszÃ©lgetÃ©s lista

    Returns:
        FormÃ¡zott string
    """
    lines = []
    for msg in conversation:
        role_label = "ğŸ‘¤ User:" if msg["role"] == "user" else "ğŸ¤– Assistant:"
        lines.append(f"{role_label} {msg['content']}")

    return "\n".join(lines)


# ============================================================================
# TESTING & EXAMPLES
# ============================================================================

if __name__ == "__main__":
    print("=== RAG Assistant Client Test ===\n")

    # Kliens lÃ©trehozÃ¡sa
    client = AssistantClient()

    # Health check
    print("1. Health check...")
    if client.health_check():
        print("   âœ“ Backend is running\n")
    else:
        print("   âœ— Backend is NOT running!")
        print("   Please start the backend: cd assistant && npm run dev")
        exit(1)

    # Single turn test
    print("2. Single turn test...")
    messages = [
        create_message("user", "Ki az a Maugli?")
    ]

    result = client.send_message(messages)

    if result["success"]:
        print(f"   âœ“ Success! (Duration: {result['metadata']['duration_ms']}ms)")
        print(f"   Response: {result['response'][:100]}...")
    else:
        print(f"   âœ— Failed: {result['error']}")

    print()

    # Multi-turn test
    print("3. Multi-turn test...")
    conversation = [
        create_message("user", "Ki az a BalÃº?"),
        create_message("assistant", "BalÃº egy medve, aki Maugli egyik tanÃ­tÃ³ja a dzsungelben."),
        create_message("user", "Mit tanÃ­t neki?")
    ]

    result = client.send_conversation(conversation)

    if result["success"]:
        print(f"   âœ“ Success! (Duration: {result['metadata']['duration_ms']}ms)")
        print(f"   Response: {result['response'][:100]}...")
    else:
        print(f"   âœ— Failed: {result['error']}")

    print("\n=== Test Complete ===")
