# ============================================================================
# Next.js Assistant Environment Configuration
# ============================================================================
# Copy this file to .env.local and update with your actual values
# IMPORTANT: Never commit .env.local to version control!

# ============================================================================
# OpenAI API Configuration
# ============================================================================

# Your OpenAI API Key (get from https://platform.openai.com/account/api-keys)
OPENAI_API_KEY=sk-proj-your-actual-key-here

# ============================================================================
# Database Configuration
# ============================================================================

# PostgreSQL connection string
# Format: postgresql://user:password@host:port/database
DATABASE_URL=postgresql://rag_user:your_secure_password@localhost:5432/rag_assistant

# ============================================================================
# Embedding Model Configuration
# ============================================================================

# OpenAI embedding model to use
# Default: text-embedding-3-small (recommended)
# Alternative: text-embedding-3-large (higher quality, more expensive)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Embedding dimension (must match the model)
# text-embedding-3-small: 1536
# text-embedding-3-large: 3072
OPENAI_EMBEDDING_DIMENSION=1536

# ============================================================================
# Vector Search Configuration
# ============================================================================

# Number of chunks to retrieve in similarity search
# Range: 1-20 (recommended: 5-10)
# Higher values: more context, slower response, higher cost
# Lower values: faster response, less context
DEFAULT_MATCH_COUNT=5

# Minimum cosine similarity threshold for vector search
# Range: 0.0-1.0
# Higher values (0.7+): only very relevant chunks
# Lower values (0.3): includes marginally relevant chunks
# Recommended: 0.3-0.5 for balanced results
DEFAULT_MATCH_THRESHOLD=0.3

# ============================================================================
# LLM Configuration (GPT-4o mini)
# ============================================================================

# Note: The chat model is currently fixed to gpt-4o-mini per requirements
# You can adjust temperature and maxTokens in the API route:
# File: app/api/chat/route.ts

# Temperature: Controls randomness/creativity (0.0-2.0)
# 0.0 = deterministic, 2.0 = highly random
# Default: 0.7 (balanced)

# Max tokens: Maximum length of generated response
# Default: 1000 tokens (approximately 750 words)

# ============================================================================
# Next.js Environment
# ============================================================================

# Set to 'development' or 'production'
NODE_ENV=development

# ============================================================================
# Notes
# ============================================================================
#
# 1. OpenAI API Key:
#    - Get from: https://platform.openai.com/account/api-keys
#    - Keep it secret - never commit to version control
#    - Costs: $0.03 per 1M embedding tokens, $0.15 per 1M input tokens (GPT-4o mini)
#
# 2. Database Configuration:
#    - Must match the PostgreSQL credentials in the root .env file
#    - Ensure PostgreSQL is running (docker-compose up -d postgres)
#    - Test connection: psql $DATABASE_URL
#
# 3. Vector Search Tuning:
#    - DEFAULT_MATCH_COUNT: Start with 5, increase to 10 for more context
#    - DEFAULT_MATCH_THRESHOLD: Start with 0.3, increase to 0.5 for higher precision
#    - Run rag-level-evaluation to find optimal values
#
# 4. Performance:
#    - Embedding generation: ~100-200ms per query
#    - Vector search: ~10-50ms
#    - LLM response: ~1-5 seconds (includes streaming)
#    - Total latency: ~2-8 seconds per response
#
# ============================================================================
